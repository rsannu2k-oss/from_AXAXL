{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc066c05-69fd-4cec-bf6e-a4cc6f301d11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### MLFlow Model Selection Use Case: Claims Prediction Model\n",
    "\n",
    "In this notebook, we will build on our Claims Prediction Model Tracking use case - and enhance it a bit, this time to find out how we can use the best model generated over multiple runs. Once the best model has been selected we will also \"download\" the model prediction function from the tracking server, and run some predictions against data that is previously unseen by the model.\n",
    "\n",
    "> **NOTE:** New to MLFlow? Head over to the [Beginners Guide to MLFlow Concepts notebook](https://eastus2.azuredatabricks.net/?o=3428697504158163#notebook/789425822738632/) and [MLFlow Tracking Use Case: Claims Prediction Model](https://eastus2.azuredatabricks.net/?o=3428697504158163#notebook/789425822738708) to learn the prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7e12134-3e0d-49de-bd08-1ea8c245620b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0691d5c5-0855-42aa-b38d-8f2ca882e589",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import mlflow\n",
    "from mlflow import create_experiment\n",
    "from mlflow import start_run\n",
    "from mlflow import log_params\n",
    "from mlflow.mleap import log_model\n",
    "from mlflow import log_metric\n",
    "from mlflow import end_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cea7f68-698f-4cbc-9f60-da0fe44d868c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Querying, Preprocessing and Train-Test Split\n",
    "\n",
    "> To reduce commentary, we have bundled multiple steps into a single command cell. For a more detailed explanation, please refer to the [MLFlow Tracking Use Case: Claims Prediction Model](https://eastus2.azuredatabricks.net/?o=3428697504158163#notebook/789425822738708)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23b04885-a33b-4708-b219-5b813425f1f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3985370938675432&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     17</span> query_skeleton <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;SELECT {data_vars} FROM dw_xle_pz.t_cps_claims WHERE original_currency = &#39;USD&#39; LIMIT 10000&#34;</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 18</span><span class=\"ansi-red-fg\"> </span>uc_DF <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>query_skeleton<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>data_vars <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;, &#34;</span><span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>numeric_X <span class=\"ansi-blue-fg\">+</span> string_X <span class=\"ansi-blue-fg\">+</span> y<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     19</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Shape of queried data: ({rows}, {cols})&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>rows <span class=\"ansi-blue-fg\">=</span> uc_DF<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> cols <span class=\"ansi-blue-fg\">=</span> len<span class=\"ansi-blue-fg\">(</span>uc_DF<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     20</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3985370938675432&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span> query_skeleton <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;SELECT {data_vars} FROM dw_xle_pz.t_cps_claims WHERE original_currency = &#39;USD&#39; LIMIT 10000&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 18</span><span class=\"ansi-red-fg\"> </span>uc_DF <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>query_skeleton<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>data_vars <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;, &#34;</span><span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>numeric_X <span class=\"ansi-blue-fg\">+</span> string_X <span class=\"ansi-blue-fg\">+</span> y<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     19</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Shape of queried data: ({rows}, {cols})&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>rows <span class=\"ansi-blue-fg\">=</span> uc_DF<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> cols <span class=\"ansi-blue-fg\">=</span> len<span class=\"ansi-blue-fg\">(</span>uc_DF<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     20</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================================================\n",
    "# Specify predictor and response variables\n",
    "\n",
    "numeric_X = [\"accident_year\", \n",
    "      \"claim_trigger_year\"]\n",
    "string_X = [\"claim_status\", \n",
    "      \"claim_cause_of_loss\", \n",
    "      \"claim_loss_location_stateprovince\", \n",
    "      \"claim_loss_location_country\", \n",
    "      \"underwriting_unit\"]\n",
    "\n",
    "y = [\"total_paid_net_act_usd\"]\n",
    "\n",
    "# ============================================================================================================\n",
    "# Pull data (only as specified in needed variables)\n",
    "\n",
    "query_skeleton = \"SELECT {data_vars} FROM dw_xle_pz.t_cps_claims WHERE original_currency = 'USD' LIMIT 10000\"\n",
    "uc_DF = spark.sql(query_skeleton.format(data_vars = \", \".join(numeric_X + string_X + y)))\n",
    "print(\"Shape of queried data: ({rows}, {cols})\".format(rows = uc_DF.count(), cols = len(uc_DF.columns)))\n",
    "\n",
    "# # ============================================================================================================\n",
    "# # Clean up nulls in dataset\n",
    "\n",
    "uc_DF = uc_DF.na.replace(\"\", None, subset=string_X)\n",
    "uc_DF = uc_DF.dropna()\n",
    "print(\"Shape of null-removed data: ({rows}, {cols})\".format(rows = uc_DF.count(), cols = len(uc_DF.columns)))\n",
    "\n",
    "# # ============================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81a4f357-e44a-43f3-970e-13d4517355c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Index + Encode String Columns and Assemble Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4775b4-e0af-4aa3-86a1-ca877b5b4bff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3985370938675434&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>   uc_DF = (StringIndexer(inputCol=col, \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                          outputCol<span class=\"ansi-blue-fg\">=</span>col <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">&#34;_ix&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">                          handleInvalid=&#34;skip&#34;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      7</span>            <span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>uc_DF<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>            .transform(uc_DF))\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/__init__.py</span> in <span class=\"ansi-cyan-fg\">wrapper</span><span class=\"ansi-blue-fg\">(self, *args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>             <span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Method %s forces keyword arguments.&#34;</span> <span class=\"ansi-blue-fg\">%</span> func<span class=\"ansi-blue-fg\">.</span>__name__<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         self<span class=\"ansi-blue-fg\">.</span>_input_kwargs <span class=\"ansi-blue-fg\">=</span> kwargs\n",
       "<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> func<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>     <span class=\"ansi-green-fg\">return</span> wrapper\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    112</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/feature.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, inputCol, outputCol, handleInvalid, stringOrderType)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2447</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2448</span>         super<span class=\"ansi-blue-fg\">(</span>StringIndexer<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__init__<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 2449</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_new_java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;org.apache.spark.ml.feature.StringIndexer&#34;</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>uid<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2450</span>         kwargs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_input_kwargs\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2451</span>         self<span class=\"ansi-blue-fg\">.</span>setParams<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_new_java_obj</span><span class=\"ansi-blue-fg\">(java_class, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             java_obj <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     66</span>         java_args <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>_py2java<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> arg<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> arg <span class=\"ansi-green-fg\">in</span> args<span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 67</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>java_args<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     68</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     69</span>     <span class=\"ansi-blue-fg\">@</span>staticmethod\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1523</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1524</span>         return_value = get_return_value(\n",
       "<span class=\"ansi-green-fg\">-&gt; 1525</span><span class=\"ansi-red-fg\">             answer, self._gateway_client, None, self._fqn)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1526</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1527</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name, value))\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    333</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>             raise Py4JError(\n",
       "\n",
       "<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling None.org.apache.spark.ml.feature.StringIndexer. Trace:\n",
       "py4j.security.Py4JSecurityException: Constructor public org.apache.spark.ml.feature.StringIndexer(java.lang.String) is not whitelisted.\n",
       "\tat py4j.security.WhitelistingPy4JSecurityManager.checkConstructor(WhitelistingPy4JSecurityManager.java:377)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:249)\n",
       "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
       "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3985370938675434&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>   uc_DF = (StringIndexer(inputCol=col, \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                          outputCol<span class=\"ansi-blue-fg\">=</span>col <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">&#34;_ix&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">                          handleInvalid=&#34;skip&#34;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      7</span>            <span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>uc_DF<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>            .transform(uc_DF))\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/__init__.py</span> in <span class=\"ansi-cyan-fg\">wrapper</span><span class=\"ansi-blue-fg\">(self, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>             <span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Method %s forces keyword arguments.&#34;</span> <span class=\"ansi-blue-fg\">%</span> func<span class=\"ansi-blue-fg\">.</span>__name__<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         self<span class=\"ansi-blue-fg\">.</span>_input_kwargs <span class=\"ansi-blue-fg\">=</span> kwargs\n<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> func<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>     <span class=\"ansi-green-fg\">return</span> wrapper\n<span class=\"ansi-green-intense-fg ansi-bold\">    112</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/feature.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, inputCol, outputCol, handleInvalid, stringOrderType)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2447</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2448</span>         super<span class=\"ansi-blue-fg\">(</span>StringIndexer<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__init__<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 2449</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_new_java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;org.apache.spark.ml.feature.StringIndexer&#34;</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>uid<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2450</span>         kwargs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_input_kwargs\n<span class=\"ansi-green-intense-fg ansi-bold\">   2451</span>         self<span class=\"ansi-blue-fg\">.</span>setParams<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_new_java_obj</span><span class=\"ansi-blue-fg\">(java_class, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             java_obj <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     66</span>         java_args <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>_py2java<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> arg<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> arg <span class=\"ansi-green-fg\">in</span> args<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">---&gt; 67</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>java_args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     69</span>     <span class=\"ansi-blue-fg\">@</span>staticmethod\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1523</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1524</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1525</span><span class=\"ansi-red-fg\">             answer, self._gateway_client, None, self._fqn)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1526</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1527</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name, value))\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    333</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>             raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling None.org.apache.spark.ml.feature.StringIndexer. Trace:\npy4j.security.Py4JSecurityException: Constructor public org.apache.spark.ml.feature.StringIndexer(java.lang.String) is not whitelisted.\n\tat py4j.security.WhitelistingPy4JSecurityManager.checkConstructor(WhitelistingPy4JSecurityManager.java:377)\n\tat py4j.Gateway.invoke(Gateway.java:249)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n</div>",
       "errorSummary": "py4j.security.Py4JSecurityException: Constructor public org.apache.spark.ml.feature.StringIndexer(java.lang.String) is not whitelisted.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoders = []\n",
    "encoded_vars = []\n",
    "for col in string_X:\n",
    "  uc_DF = (StringIndexer(inputCol=col, \n",
    "                         outputCol=col + \"_ix\", \n",
    "                         handleInvalid=\"skip\")\n",
    "           .fit(uc_DF)\n",
    "           .transform(uc_DF))\n",
    "  encoders.append(OneHotEncoder(inputCol=col + \"_ix\", \n",
    "                                outputCol=col + \"_enc\"))\n",
    "  encoded_vars.append(col + \"_enc\")\n",
    "  \n",
    "assembler = (VectorAssembler()\n",
    "             .setInputCols(numeric_X + encoded_vars)\n",
    "             .setOutputCol(\"features\"))\n",
    "\n",
    "classifier = LinearRegression(featuresCol=\"features\", \n",
    "                              labelCol=y[0], \n",
    "                              maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=encoders + [assembler, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16c99d65-3de9-474b-8782-cec5a09c0d29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a Parameter Grid to track how model validation changes on MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b03e257-78e2-4b96-bef9-637c7e063be4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(classifier.elasticNetParam, [0.6, 0.85, 0.2, 0.05])\n",
    "             .addGrid(classifier.regParam, [0.3, 0.7, 0.5, 0.1])\n",
    "             .build())\n",
    "\n",
    "# # ============================================================================================================\n",
    "# # Train-Test Split (3:1 ratio)\n",
    "trainValidSplit = TrainValidationSplit(estimator=pipeline, \n",
    "                                       estimatorParamMaps=paramGrid, \n",
    "                                       evaluator=RegressionEvaluator(labelCol=y[0], \n",
    "                                                                     predictionCol=\"prediction\", \n",
    "                                                                     metricName=\"rmse\"), \n",
    "                                       trainRatio=0.75, \n",
    "                                       parallelism=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ab061eb-8765-46c3-8e48-9a9249e00dac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Train a `LinearRegression` model and track prediction accuracies with MLFlow Runs\n",
    "> **NOTE:** This is where you will find some deviations from the previous version of the use case. \n",
    "\n",
    "> 1. We are explicitly creating the experiment instead of letting Databricks autogenerate it for us. This helps in controlling the identifier of this experiment, and helps in \"querying\" all the runs (we will get to that in subsequent cells).\n",
    "\n",
    "> 2. During the Run, we have now introduced a model logging step (look for the `log_model()` function). This helps us to not only track the performance of a model within each run, but saves the model predictor function itself. At a later stage, when we settle on the \"best model\", we will directly download the predictor for it and use it for predicting on unforeseen data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b1ab1ab-4c64-4055-b598-60b763509dcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new experiment and track it's ID\n",
    "experiment_id = create_experiment(name=\"/Users/souradeep.sinha@axaxl.com/claims_sample_model_selection\")\n",
    "\n",
    "# Start Run\n",
    "with start_run(experiment_id=experiment_id):\n",
    "  \n",
    "  # Fit the model. This will automatically track metrics and parameters\n",
    "  model = trainValidSplit.fit(uc_DF)\n",
    "  \n",
    "  # Log an extra metric\n",
    "  log_metric(\"bestRMSE\", min(model.validationMetrics))\n",
    "  \n",
    "  # Log the best model to this run\n",
    "  mlflow.spark.log_model(model.bestModel, \"model-file\")   \n",
    "  \n",
    "  # End Run\n",
    "  end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66a0b3b8-d3fe-4d76-a617-eddfcfc49b8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> **NOTE:** \n",
    "\n",
    "> Experiments are tracked under user accounts. In the previous cell, the author of this notebook has created one under his account path. For any other user, they will have to input their own path to create an experiment successfully.\n",
    "\n",
    "> Since we are creating an explicit experiment, this will \"detach\" all experiment activity from the current notebook. As a result, the **`Runs`** panel will not reflect any activity. On the other hand, if you are looking into your **`Home`** folder, you should find the experiment created under the same name, with all activity tracked and intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a995321-5f88-4db2-bba8-20d41a3f4bfe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> **NOTE:** Interested in learning more about MLFlow? There's a wealth of documentation under [MLFlow](https://www.mlflow.org/docs/latest/tracking.html) and [Databricks](https://docs.databricks.com/applications/mlflow/quick-start.html) that you can review and use according to your needs.\n",
    "\n",
    "> For questions, please reach out to the [Data Analytics Workbench email](mailto:EDS-DEEP-Workbench-Business-Support@axaxl.com) or our [support channel on Teams](https://teams.microsoft.com/l/channel/19%3afec947f0c9144bcbad26b5a245e0080e%40thread.skype/Ask%2520Workbench%2520Support?groupId=18b5e01c-2032-4dbb-ab5a-8aeb6f79968f&tenantId=53b7cac7-14be-46d4-be43-f2ad9244d901)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "workbench_mlflow_uc_model_selection_py",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
